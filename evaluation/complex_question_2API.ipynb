{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a77ff93",
   "metadata": {},
   "source": [
    "将复杂任务拆分成原子任务，并且为每个原子任务寻找与之相匹配的API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7d897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./ai_agent/mvbech_file/complex.json', 'r') as file:\n",
    "    complex_question_list = json.load(file)\n",
    "print(len(complex_question_list))\n",
    "print(complex_question_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecaee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置环境变量和API密钥\n",
    "import os\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://10.16.64.223:7890\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://10.16.64.223:7890\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# 创建聊天模型\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "model_name = 'gpt-4'\n",
    "llm = ChatOpenAI(model_name=model_name,temperature=0)\n",
    "\n",
    "# 设定 AI 的角色和目标\n",
    "role_template= \"\"\"\n",
    "You are going to decompose a complex question step by step about video into following atomic operation, and use according tools to solve the problem.\n",
    "You can only use the following tools to solve the problem:\n",
    "Object Tracking: \n",
    "    Function: Identifying and tracking specific objects in videos, typically involving the analysis of object positions and movements.\n",
    "    Input: File path of Video.\n",
    "    API name: ObjectTrackingTool()\n",
    "    Output: Positions and movements of specific objects in each frame.\n",
    "Face Detection and Recognition: \n",
    "    Function: Detecting and recognizing faces in videos, which may include emotion analysis.\n",
    "    Input: File path of Video.\n",
    "    API name: VideoFaceRecognitionTool()\n",
    "GPT Video Summarization: \n",
    "    Function: Extracting key frames or segments from videos to create a summary and reduce the video's duration.\n",
    "    Input: File path of Video.\n",
    "    API name: GPTVideoSummarizationTool()\n",
    "\"\"\"\n",
    "\n",
    "# role_template= \"\"\"\n",
    "# You are going to decompose a complex question step by step about video into following atomic operation, and use according tools to solve the problem.\n",
    "# Video Classification: \n",
    "#     Function: Classifying videos into categories such as movie genres, sports events, news, etc. \n",
    "#     Input: File path of Video.\n",
    "#     Output: Category of the video.\n",
    "#     API name: VideoClassificationTool()\n",
    "# Object Detection and Tracking: \n",
    "#     Function: Identifying and tracking specific objects in videos, typically involving the analysis of object positions and movements.\n",
    "#     Input: File path of Video.\n",
    "#     Output: Positions and movements of specific objects in each frame.\n",
    "#     API name: VideoObjectDetectionTool(), YOLOVideoObjectTrackingTool()\n",
    "# Action Recognition: \n",
    "#     Function: Recognizing actions in videos, understanding the behavior of people or objects in the video.\n",
    "#     Input: File path of Video.\n",
    "#     Output: Action type in each frame.\n",
    "#     API name: VideoActionRecognitionTool()\n",
    "# Gesture Recognition: \n",
    "#     Function: Identifying and understanding gestures of the human body or devices in videos.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoGestureRecognitionTool()\n",
    "# Video Generation: \n",
    "#     Function: Generating new video content using generative models.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoGenerationTool()\n",
    "# Video Summarization: \n",
    "#     Function: Extracting key frames or segments from videos to create a summary and reduce the video's duration.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoSummarizationTool()\n",
    "# Video Segmentation: \n",
    "#     Function: Dividing videos into different parts, usually based on scenes or objects.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoSegmentationTool()\n",
    "# Face Detection and Recognition: \n",
    "#     Function: Detecting and recognizing faces in videos, which may include emotion analysis.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoFaceDetectionTool(), VideoFaceRecognitionTool()\n",
    "# Video Captioning: \n",
    "#     Function: Automatically generating textual descriptions for videos, explaining the content.\n",
    "#     Input: File path of Video.\n",
    "#     API name: VideoCaptioningTool()\n",
    "# \"\"\"\n",
    "# CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）\n",
    "\n",
    "cot_template = \"\"\"\n",
    "Here is an example of what you need to do:\n",
    "\n",
    "As a video problem solver, my job is breaking down complex question step by step using the mentioned tools.\n",
    "First, I will analysis the question to find which kind of information are needed to answer the question.\n",
    "Second, I will find the most suitable tools to get each kind information, give the format of input and output.\n",
    "\n",
    "Example:\n",
    "Human: What happened after the person took the food? Options: (A) Ate the medicine. (B) Tidied up the blanket. (C) Put down the cup/glass/bottle. (D) Took the box.\n",
    "AI: \n",
    "Question Analysis: The question is about understanding what happened after a person took the food. To answer this, we need information related to the actions and events that occurred after the person took the food.\n",
    "Suitable Tools(different number of tools to different problem): example: 1. Video Classification, 2. Object Detection and Tracking, 3. Action Recognition\n",
    "\n",
    "\"\"\"\n",
    "# sample=\"\"\"\n",
    "# API:\n",
    "# Video Classification: \n",
    "#     Fucntion: To identify the category of the video.\n",
    "#     Input: File path of Video.\n",
    "#     Output: Category of the video.\n",
    "# Object Detection and Tracking: \n",
    "#     Fucntion: To identify and track the specific object (food) in the video, analyzing its position and movement. \n",
    "#     Input: File path of Video.\n",
    "#     Output: Positions and movements of specific objects in each frame.\n",
    "# Action Recognition: \n",
    "#     Fucntion: To recognize the actions related to taking the food, understanding the behavior of the person in the video. \n",
    "#     Input: File path of Video.\n",
    "#     Output: Action type in each frame.\n",
    "# \"\"\"\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "system_prompt_role = SystemMessagePromptTemplate.from_template(role_template)\n",
    "system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template)\n",
    "\n",
    "# # 用户的询问\n",
    "human_template = \"{human_input}\"\n",
    "human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 将以上所有信息结合为一个聊天提示\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt])\n",
    "\n",
    "question_complex=complex_question_list[999].get('question')\n",
    "print(question_complex)\n",
    "\n",
    "# prompt = chat_prompt.format_prompt(human_input=question_complex).to_messages()\n",
    "\n",
    "# # 接收用户的询问，返回回答结果\n",
    "# response = llm(prompt)\n",
    "# print(str(response).replace('\\\\n','\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425424f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for complex_question in complex_question_list:\n",
    "    if complex_question.get('id') == 903:\n",
    "        print(complex_question)\n",
    "        prompt = chat_prompt.format_prompt(human_input=complex_question).to_messages()\n",
    "        # 接收用户的询问，返回回答结果\n",
    "        response = llm(prompt)\n",
    "        print(str(response).replace('\\\\n','\\n'))\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
